---
name: Tests - Integration - Generic Operator based

permissions:
    contents: read # don't allow commits
    pull-requests: write # allow comments, labels (used by internal-apply-skip-label)

on:
    schedule:
        - cron: 0 2 * * 1 # Runs at 2 AM on Monday
    pull_request:
        paths:
            - .github/workflows/generic_kubernetes_operator_based_test.yml
            - .github/workflows-config/generic-kubernetes-operator-based/test_matrix.yml
            - .tool-versions
            - generic/kubernetes/operator-based/**
            - aws/openshift/rosa-hcp-single-region/**
            - '!aws/openshift/rosa-hcp-single-region/test/golden/**'
            - aws/kubernetes/eks-single-region-irsa/**
            - '!aws/kubernetes/eks-single-region-irsa/test/golden/**'
            - .github/actions/aws-openshift-rosa-hcp-single-region-create/**
            - .github/actions/aws-kubernetes-eks-single-region-create/**
            - .github/actions/aws-generic-terraform-cleanup/**
            - .github/actions/aws-configure-cli/**
            - .github/actions/internal-helm-chart-tests/**
            - .github/actions/internal-apply-skip-label/**
            - .github/actions/internal-generic-encrypt-export/**
            - .github/actions/internal-generic-decrypt-import/**
            - .github/actions/internal-tests-matrix/**
            - .github/actions/internal-clean-namespace/**
            - .github/actions/kubernetes-restart-coredns/**
            - .github/actions/aws-kubernetes-ingress-setup/**
            - .github/actions/kubernetes-wildcard-certificate/**

    workflow_dispatch:
        inputs:
            cluster_name:
                description: Cluster name.
                required: false
                type: string
            delete_clusters:
                description: Whether to delete the clusters.
                type: boolean
                default: true
            enable_tests:
                description: Whether to enable the tests.
                type: boolean
                default: true

            ref-arch:
                description: |
                    Reference architecture to use, can only deploy one at a time.
                    Use a different trigger with unique names for each ref-arch.
                    Valid values are `operator-based`.
                    Only for workflow_dispatch.
                required: false
                type: string
                default: operator-based

            use_wildcard_cert:
                description: Use wildcard certificate from Vault instead of ACME/Let's Encrypt
                type: boolean
                default: false

# limit to a single execution per actor of this workflow
concurrency:
    group: ${{ github.workflow }}-${{ github.ref }}
    # we don't cancel the previous run, so it can finish it and let clusters in a proper state
    cancel-in-progress: false

env:
    IS_SCHEDULE: ${{ (contains(github.head_ref, 'schedules/') || github.event_name == 'schedule') && 'true' || 'false' }}

    IS_RENOVATE_PR: ${{ github.event_name == 'pull_request' && github.event.pull_request.user.login == 'renovate[bot]' }}

    AWS_PROFILE: infex
    AWS_REGION: eu-west-2
    S3_BACKEND_BUCKET: tests-ra-aws-rosa-hcp-tf-state-eu-central-1
    S3_BUCKET_REGION: eu-central-1
    TF_MODULES_DIRECTORY: ./.tf-modules-workflow/   # where the tf repo will be clone

    # keep it synced with ROSA single region so we have the cleanup
    # maybe later we could extract this in a common file
    S3_BACKEND_BUCKET_PREFIX_ROSA_HCP_SINGLE_REGION: aws/openshift/rosa-hcp-single-region/
    S3_BACKEND_BUCKET_PREFIX_EKS_SINGLE_REGION: aws/kubernetes/eks-single-region/

    CLEANUP_CLUSTERS: ${{ github.event.inputs.delete_clusters || 'true' }}

    # TEST VARIABLES

    # Vars with "CI_" prefix are used in the CI workflow only.
    CI_MATRIX_FILE: .github/workflows-config/generic-kubernetes-operator-based/test_matrix.yml

    # Docker Hub auth to avoid image pull rate limit.
    # Vars with "TEST_" prefix are used in the test runner tool (Task).
    TESTS_ENABLED: ${{ github.event.inputs.enable_tests || 'true' }}

    # renovate: datasource=github-tags depName=camunda/camunda-platform-helm
    # TODO: resolve this branch when merging to playwright
    TESTS_CAMUNDA_HELM_CHART_REPO_REF: fix-venom-8-8   # git reference used to clone the camunda/camunda-platform-helm repository to perform the tests
    TESTS_CAMUNDA_HELM_CHART_REPO_PATH: ./.camunda_helm_repo   # where to clone it

    ROSA_CLI_VERSION: latest

jobs:
    triage:
        runs-on: ubuntu-latest
        outputs:
            should_skip: ${{ steps.skip_check.outputs.should_skip }}
        steps:
            - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6
            - name: Check labels
              id: skip_check
              uses: ./.github/actions/internal-triage-skip

    clusters-info:
        needs:
            - triage
        if: needs.triage.outputs.should_skip == 'false'
        name: Define Matrix
        runs-on: ubuntu-latest
        outputs:
            platform-matrix: ${{ steps.matrix.outputs.platform_matrix }}
        steps:
            - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6
              with:
                  fetch-depth: 0

            - name: Install asdf tools with cache
              uses: camunda/infraex-common-config/./.github/actions/asdf-install-tooling@193a21e1e56c9a65517a822224ac3b4ffa4d6ae4 # 1.5.9

            - name: Define tests matrix
              uses: ./.github/actions/internal-tests-matrix
              id: matrix
              with:
                  ci_matrix_file: ${{ env.CI_MATRIX_FILE }}
                  cluster_name: ${{ inputs.cluster_name }}
                  ref_arch: ${{ inputs.ref-arch }}
                  is_schedule: ${{ env.IS_SCHEDULE }}
                  is_renovate_pr: ${{ env.IS_RENOVATE_PR }}

    prepare-clusters:
        name: Prepare clusters
        needs:
            - clusters-info
        strategy:
            fail-fast: false
            matrix:
                distro: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).distro }}
                scenario: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).scenario }}
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6
              with:
                  ref: ${{ github.ref }}
                  fetch-depth: 0

            - name: Install asdf tools with cache
              uses: camunda/infraex-common-config/./.github/actions/asdf-install-tooling@193a21e1e56c9a65517a822224ac3b4ffa4d6ae4 # 1.5.9

            - name: Import Secrets
              id: secrets
              uses: hashicorp/vault-action@4c06c5ccf5c0761b6029f56cfb1dcf5565918a3b # v3
              with:
                  url: ${{ secrets.VAULT_ADDR }}
                  method: approle
                  roleId: ${{ secrets.VAULT_ROLE_ID }}
                  secretId: ${{ secrets.VAULT_SECRET_ID }}
                  exportEnv: false
                  secrets: |
                      secret/data/products/infrastructure-experience/ci/common RH_OPENSHIFT_TOKEN;
                      secret/data/products/infrastructure-experience/ci/common CI_OPENSHIFT_MAIN_PASSWORD;
                      secret/data/products/infrastructure-experience/ci/common CI_OPENSHIFT_MAIN_USERNAME;
                      secret/data/products/infrastructure-experience/ci/common CI_ENCRYPTION_KEY;

            - name: Configure AWS CLI
              uses: ./.github/actions/aws-configure-cli
              with:
                  vault-addr: ${{ secrets.VAULT_ADDR }}
                  vault-role-id: ${{ secrets.VAULT_ROLE_ID }}
                  vault-secret-id: ${{ secrets.VAULT_SECRET_ID }}
                  aws-profile: ${{ env.AWS_PROFILE }}
                  aws-region: ${{ env.AWS_REGION }}

            - name: Set current target branch
              id: target-branch
              run: |
                  set -euo pipefail
                  TARGET_BRANCH=$(cat .target-branch)
                  echo "TARGET_BRANCH=$TARGET_BRANCH" | tee -a "$GITHUB_OUTPUT"

            - name: Create ROSA cluster and login
              uses: ./.github/actions/aws-openshift-rosa-hcp-single-region-create
              id: create_rosa_cluster
              # Do not interrupt tests; otherwise, the Terraform state may become inconsistent.
              if: always() && success() && matrix.distro.type == 'openshift'
              with:
                  rh-token: ${{ steps.secrets.outputs.RH_OPENSHIFT_TOKEN }}
                  cluster-name: ${{ matrix.distro.clusterName }}-${{matrix.scenario.shortName }}
                  admin-username: ${{ steps.secrets.outputs.CI_OPENSHIFT_MAIN_USERNAME }}
                  admin-password: ${{ steps.secrets.outputs.CI_OPENSHIFT_MAIN_PASSWORD }}
                  aws-region: ${{ env.AWS_REGION }}
                  s3-backend-bucket: ${{ env.S3_BACKEND_BUCKET }}
                  s3-bucket-region: ${{ env.S3_BUCKET_REGION }}
                  s3-bucket-key-prefix: ${{ env.S3_BACKEND_BUCKET_PREFIX_ROSA_HCP_SINGLE_REGION }}${{ steps.target-branch.outputs.TARGET_BRANCH }}/
                  openshift-version: ${{ matrix.distro.version }}
                  tf-modules-revision: ${{ github.ref }}
                  tf-modules-path: ${{ env.TF_MODULES_DIRECTORY }}
                  cleanup-tf-modules-path: 'false'

                  tags: >
                      {
                        "ci-run-id": "${{ github.run_id }}",
                        "ci-run-number": "${{ github.run_number }}",
                        "ci-workflow": "${{ github.workflow }}",
                        "ci-actor": "${{ github.actor }}",
                        "ci-ref": "${{ github.ref }}",
                        "ci-commit": "${{ github.sha }}",
                        "ci-repo": "${{ github.repository }}",
                        "ci-event": "${{ github.event_name }}",
                        "map-migrated": "migARUADZHVWZ"
                      }

            - name: Create EKS cluster and login
              uses: ./.github/actions/aws-kubernetes-eks-single-region-create
              id: create_eks_cluster
              # Do not interrupt tests; otherwise, the Terraform state may become inconsistent.
              if: always() && success() && matrix.distro.type == 'eks'
              with:
                  cluster-name: ${{ matrix.distro.clusterName }}-${{matrix.scenario.shortName }}
                  aws-region: ${{ env.AWS_REGION }}
                  s3-backend-bucket: ${{ env.S3_BACKEND_BUCKET }}
                  s3-bucket-region: ${{ env.S3_BUCKET_REGION }}
                  s3-bucket-key-prefix: ${{ env.S3_BACKEND_BUCKET_PREFIX_EKS_SINGLE_REGION }}${{ steps.target-branch.outputs.TARGET_BRANCH }}/
                  tf-modules-revision: ${{ github.ref }}
                  tf-modules-path: ${{ env.TF_MODULES_DIRECTORY }}
                  ref-arch: eks-single-region
                  deploy-aurora: 'false'      # Disabled - using CloudNativePG operator instead
                  deploy-opensearch: 'false'  # Disabled - using ECK operator instead
                  tags: >
                      {
                        "ci-run-id": "${{ github.run_id }}",
                        "ci-run-number": "${{ github.run_number }}",
                        "ci-workflow": "${{ github.workflow }}",
                        "ci-actor": "${{ github.actor }}",
                        "ci-ref": "${{ github.ref }}",
                        "ci-commit": "${{ github.sha }}",
                        "ci-repo": "${{ github.repository }}",
                        "ci-event": "${{ github.event_name }}",
                        "map-migrated": "migARUADZHVWZ"
                      }
            - name: Dump kubeconfig before encryption
              run: |
                  set -euo pipefail

                  kubectl config view --raw > "${{ runner.temp }}/kubeconfig.yaml"

            - name: Export kubeconfig and encrypt it # this is required to pass matrix outputs securely using artifacts
              id: export_kube_config
              uses: ./.github/actions/internal-generic-encrypt-export
              with:
                  file_path: ${{ runner.temp }}/kubeconfig.yaml
                  encryption_key: ${{ steps.secrets.outputs.CI_ENCRYPTION_KEY }}


            # We are exporting everything for irsa and non-irsa, worst case it's empty and not used
            # Reason for skipping pipefail in the next step
            - name: Dump relevant Terraform outputs for cluster module
              if: always() && matrix.distro.type != 'openshift'
              working-directory: ${{ env.TF_MODULES_DIRECTORY }}aws/kubernetes/eks-single-region/terraform/cluster/
              id: dump_outputs
              run: |
                  set -euo pipefail

                  source ${{ github.workspace }}/.github/scripts/gha-functions.sh

                  export_new_env_vars_to_file \
                      ${{ github.workspace }}/aws/kubernetes/eks-single-region/procedure/export-helm-values.sh

            - name: Export other secrets from the action # this is required to pass matrix outputs securely using artifacts
              id: encrypt_outputs
              if: always() && matrix.distro.type != 'openshift'
              uses: ./.github/actions/internal-generic-encrypt-export
              with:
                  file_path: ${{ runner.temp }}/outputs_raw
                  encryption_key: ${{ steps.secrets.outputs.CI_ENCRYPTION_KEY }}

            ## Write for matrix outputs workaround
            - uses: cloudposse/github-action-matrix-outputs-write@ed06cf3a6bf23b8dce36d1cf0d63123885bb8375 # v1
              if: always()
              id: out
              with:
                  matrix-step-name: ${{ github.job }}
                  matrix-key: ${{ matrix.distro.name }}-${{ matrix.scenario.name }}
                  outputs: |-
                      outputs_raw: ${{ matrix.distro.type != 'openshift' && steps.encrypt_outputs.outputs.encrypted_file_base64 || '' }}
                      kubeconfig_encrypted: ${{ steps.export_kube_config.outputs.encrypted_file_base64 }}

    access-info:
        name: Read kube configs from matrix
        runs-on: ubuntu-latest
        needs: prepare-clusters
        outputs:
            config: ${{ steps.read-workflow.outputs.result }}
        steps:
            - uses: cloudposse/github-action-matrix-outputs-read@33cac12fa9282a7230a418d859b93fdbc4f27b5a # v1
              id: read-workflow
              with:
                  matrix-step-name: prepare-clusters

    integration-tests:
        name: Run integration tests - ${{ matrix.distro.name }} - ${{ matrix.scenario.name }} - ${{ matrix.declination.name }}
        runs-on: ubuntu-latest
        needs:
            - clusters-info
            - access-info
        strategy:
            fail-fast: false
            matrix:
                distro: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).distro }}
                scenario: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).scenario }}
                declination: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).declination }}
        concurrency:
            # instead of running sequentially in a matrix, we use concurrency to run the different scenarios
            # in parallel but the declinations sequentially
            # max-parallel would limit us to run 1 matrix job but this way we can run 2 jobs in parallel.
            group: ${{ github.workflow }}-${{ github.ref }}-${{ matrix.distro.name }}-${{ matrix.scenario.name }}
            cancel-in-progress: false
        env:
            # https://github.com/camunda/camunda-platform-helm/blob/test/integration/scenarios/chart-full-setup/Taskfile.yaml#L12C15-L12C32
            TEST_CLUSTER_TYPE: ${{ matrix.distro.type == 'openshift' && 'openshift' || 'kubernetes' }}
            CAMUNDA_NAMESPACE: camunda
            # Do not change this secret name without updating manifests that reference this TLS secret
            WILDCARD_TLS_SECRET_NAME: camunda-tls
        steps:
            - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6

            - name: Install asdf tools with cache for the project
              uses: camunda/infraex-common-config/./.github/actions/asdf-install-tooling@193a21e1e56c9a65517a822224ac3b4ffa4d6ae4 # 1.5.9

            - name: Install CLI tools from OpenShift Mirror
              uses: redhat-actions/openshift-tools-installer@144527c7d98999f2652264c048c7a9bd103f8a82 # v1
              if: matrix.distro.type == 'openshift'
              with:
                  oc: ${{ matrix.distro.version }}

            - name: Import Secrets
              id: secrets
              uses: hashicorp/vault-action@4c06c5ccf5c0761b6029f56cfb1dcf5565918a3b # v3
              with:
                  url: ${{ secrets.VAULT_ADDR }}
                  method: approle
                  roleId: ${{ secrets.VAULT_ROLE_ID }}
                  secretId: ${{ secrets.VAULT_SECRET_ID }}
                  exportEnv: false
                  secrets: |
                      secret/data/products/infrastructure-experience/ci/common DOCKERHUB_USER;
                      secret/data/products/infrastructure-experience/ci/common DOCKERHUB_PASSWORD;
                      secret/data/products/infrastructure-experience/ci/common CI_CAMUNDA_USER_TEST_CLIENT_ID;
                      secret/data/products/infrastructure-experience/ci/common CI_CAMUNDA_USER_TEST_CLIENT_SECRET;
                      secret/data/products/infrastructure-experience/ci/common CI_ENCRYPTION_KEY;

            - name: Configure AWS CLI for EKS access
              uses: ./.github/actions/aws-configure-cli
              if: matrix.distro.type == 'eks'
              with:
                  vault-addr: ${{ secrets.VAULT_ADDR }}
                  vault-role-id: ${{ secrets.VAULT_ROLE_ID }}
                  vault-secret-id: ${{ secrets.VAULT_SECRET_ID }}
                  aws-profile: ${{ env.AWS_PROFILE }}
                  aws-region: ${{ env.AWS_REGION }}

            - name: üö¢ Retrieve environment variables from outputs
              if: matrix.distro.type != 'openshift'
              uses: ./.github/actions/internal-generic-decrypt-import
              with:
                  output_path: ${{ runner.temp }}/outputs_raw
                  encrypted_file_base64: >
                      ${{ fromJson(needs.access-info.outputs.config).outputs_raw[
                        format(
                          '{0}-{1}',
                          matrix.distro.name,
                          matrix.scenario.name
                        )
                      ] }}
                  encryption_key: ${{ steps.secrets.outputs.CI_ENCRYPTION_KEY }}

            - name: üö¢ Export outputs as environment variables
              if: matrix.distro.type != 'openshift'
              timeout-minutes: 3
              run: |
                  set -euo pipefail
                  source .github/scripts/gha-functions.sh
                  export_file_to_github_env "${{ runner.temp }}/outputs_raw"

            - name: Retrieve kubeconfig from outputs
              uses: ./.github/actions/internal-generic-decrypt-import
              with:
                  output_path: ${{ runner.temp }}/kubeconfig
                  encrypted_file_base64: >
                      ${{ fromJson(needs.access-info.outputs.config).kubeconfig_encrypted[
                        format(
                          '{0}-{1}',
                          matrix.distro.name,
                          matrix.scenario.name
                        )
                      ] }}
                  encryption_key: ${{ steps.secrets.outputs.CI_ENCRYPTION_KEY }}

            - name: üîê Login into the cluster
              timeout-minutes: 2
              run: |
                  set -euo pipefail

                  mkdir -p "$HOME/.kube"
                  mv "${{ runner.temp }}/kubeconfig" "$HOME/.kube/config"

                  kubectl config current-context
                  kubectl get nodes

            - name: üìÅ Get a copy of the reference architecture
              timeout-minutes: 10
              run: |
                  # run it as specified in the doc
                  set -euo pipefail
                  ./generic/kubernetes/operator-based/get-your-copy.sh
                  tree

            - name: üèóÔ∏è Clean PostgreSQL operator namespace
              uses: ./.github/actions/internal-clean-namespace
              timeout-minutes: 10
              with:
                  namespace: cnpg-system

            - name: üèóÔ∏è Clean Elasticsearch operator namespace
              timeout-minutes: 10
              uses: ./.github/actions/internal-clean-namespace
              with:
                  namespace: elastic-system

            - name: üèóÔ∏è Clean and recreate Camunda namespace
              timeout-minutes: 20
              uses: ./.github/actions/internal-clean-namespace
              with:
                  namespace: ${{ env.CAMUNDA_NAMESPACE }}
                  recreate: 'true'

            - name: Wait for cluster stability
              run: sleep 30

            # Use wildcard certificates from Vault instead of ACME/Let's Encrypt
            # This is useful during testing phase to avoid Let's Encrypt rate limits (max 50 certificates per week)
            - name: Configure wildcard certificate usage
              id: cert-config
              uses: ./.github/actions/internal-configure-wildcard-cert
              with:
                  manual-wildcard-cert: ${{ github.event.inputs.use_wildcard_cert }}
                  is-renovate-pr: ${{ env.IS_RENOVATE_PR }}
                  is-schedule: ${{ env.IS_SCHEDULE }}
                  base-ref: ${{ github.base_ref }}

            - name: üå± Register chart setup environment values
              timeout-minutes: 3
              run: |
                  set -euo pipefail
                  source .github/scripts/gha-functions.sh
                  export_new_env_vars generic/kubernetes/operator-based/0-set-environment.sh

            - name: üõ†Ô∏è Assemble deployment values
              timeout-minutes: 10
              working-directory: ./generic/kubernetes/operator-based/
              run: |
                  set -o errexit
                  set -euo pipefail

                  echo "Applying declination: ${{ matrix.declination.name }} for cluster type: ${{ matrix.distro.type }}"

                  # Assemble base configuration files
                  VALUES_FILES=(
                      "tests/utils/camunda-base-values.yml"
                  )

                  if [[ "${{ matrix.declination.name }}" == "domain" ]]; then
                      # Set domain and ingress class based on cluster type
                      if [[ "${{ matrix.distro.type }}" == "openshift" ]]; then
                          echo "Getting OpenShift apps domain..."
                          source tests/utils/get-oc-app-domain.sh
                          BASE_DOMAIN="$OPENSHIFT_APPS_DOMAIN"
                          INGRESS_CLASS_NAME="openshift-default"

                          echo "Enable HTTP/2 on OpenShift Ingress Controller"
                          source ./../../openshift/single-region/procedure/get-ingress-http2-status.sh
                          ./../../openshift/single-region/procedure/enable-ingress-http2.sh
                      else
                          # EKS and other Kubernetes clusters use camunda.ie
                          BASE_DOMAIN="camunda.ie"
                          INGRESS_CLASS_NAME="nginx"
                      fi

                      CAMUNDA_DOMAIN="${{ matrix.distro.clusterName }}-${{ matrix.scenario.shortName }}.$BASE_DOMAIN"
                      echo "INGRESS_CLASS_NAME=$INGRESS_CLASS_NAME" | tee -a "$GITHUB_ENV"
                      VALUES_FILES+=("tests/utils/camunda-domain-values.yml")
                  else
                      # No-domain: everything on localhost
                      CAMUNDA_DOMAIN="localhost"
                  fi

                  echo "CAMUNDA_DOMAIN=$CAMUNDA_DOMAIN" | tee -a "$GITHUB_ENV"
                  export CAMUNDA_DOMAIN
                  export INGRESS_CLASS_NAME

                  # Add component-specific configurations
                  VALUES_FILES+=(
                    "postgresql/camunda-identity-values.yml"
                    "postgresql/camunda-webmodeler-values.yml"
                    "elasticsearch/camunda-elastic-values.yml"
                    "tests/utils/camunda-values-identity-secrets.yml"
                    "tests/helm-values/identity.yml"
                    "tests/helm-values/registry.yml"
                  )

                  # Add OpenShift-specific SCC configuration
                  if [[ "${{ matrix.distro.type }}" == "openshift" ]]; then
                      echo "Adding OpenShift Security Context Constraints configuration..."
                      VALUES_FILES+=("../../../generic/openshift/single-region/helm-values/scc.yml")
                  fi

                  # Add Keycloak configuration based on domain setup
                  if [[ "${{ matrix.declination.name }}" == "domain" ]]; then
                      VALUES_FILES+=("keycloak/camunda-keycloak-domain-values.yml")
                  else
                      VALUES_FILES+=("keycloak/camunda-keycloak-no-domain-values.yml")
                  fi

                  # Create final assembled values file using yq
                  echo "Assembling final values file from: ${VALUES_FILES[*]}"
                  yq eval-all ". as \$item ireduce ({}; . *+ \$item)" "${VALUES_FILES[@]}" > camunda-assembled-values-raw.yml

                  # Process and merge OpenShift route configurations for domain setups
                  # Adjust TLS configuration based on cluster type and wildcard cert usage
                  if [[ "${{ matrix.distro.type }}" == "openshift" && "${{ matrix.declination.name }}" == "domain" ]]; then
                      echo "Processing and merging OpenShift route configurations (orchestration + connectors)..."

                      # Process both orchestration-route.yml and connectors-route.yml with envsubst
                      envsubst < "../../../generic/openshift/single-region/helm-values/orchestration-route.yml" > orchestration-route-processed.yml
                      envsubst < "../../../generic/openshift/single-region/helm-values/connectors-route.yml" > connectors-route-processed.yml

                      # Merge processed routes with assembled values and apply TLS adjustments
                      yq eval-all ". as \$item ireduce ({}; . *+ \$item)" \
                        camunda-assembled-values-raw.yml \
                        orchestration-route-processed.yml \
                        connectors-route-processed.yml | \
                      yq eval '
                        del(.global.ingress.annotations."kubernetes.io/tls-acme") |
                        .global.ingress.annotations."route.openshift.io/termination" = "edge" |
                        .global.ingress.tls.secretName = "-" |
                        del(.orchestration.ingress.grpc.annotations."kubernetes.io/tls-acme") |
                        .orchestration.ingress.grpc.tls.secretName = "-"
                      ' > camunda-assembled-values-raw-temp.yml
                      mv camunda-assembled-values-raw-temp.yml camunda-assembled-values-raw.yml

                  elif [[ "${{ steps.cert-config.outputs.use-wildcard-cert }}" == "true" && "${{ matrix.declination.name }}" == "domain" ]]; then
                      echo "Configuring wildcard certificate from Vault..."
                      echo "Using TLS secret: ${{ env.WILDCARD_TLS_SECRET_NAME }}"
                      yq eval '
                        del(.global.ingress.annotations."kubernetes.io/tls-acme") |
                        del(.global.ingress.annotations."cert-manager.io/cluster-issuer") |
                        .global.ingress.tls.secretName = "${{ env.WILDCARD_TLS_SECRET_NAME }}" |
                        del(.orchestration.ingress.grpc.annotations."kubernetes.io/tls-acme") |
                        del(.orchestration.ingress.grpc.annotations."cert-manager.io/cluster-issuer") |
                        .orchestration.ingress.grpc.tls.secretName = "${{ env.WILDCARD_TLS_SECRET_NAME }}"
                      ' camunda-assembled-values-raw.yml > camunda-assembled-values-raw-tls.yml
                      mv camunda-assembled-values-raw-tls.yml camunda-assembled-values-raw.yml
                  fi

                  # Apply envsubst to the assembled file for variable substitution
                  echo "Processing assembled values with envsubst for variable substitution..."
                  envsubst < camunda-assembled-values-raw.yml > camunda-assembled-values.yml

                  echo "Final assembled values file created: camunda-assembled-values.yml"
                  echo "Preview of assembled configuration:"
                  cat camunda-assembled-values.yml

            - name: üßπ Clean ingress components for EKS domain setup
              if: ${{ matrix.distro.type == 'eks' && matrix.declination.name == 'domain' }}
              timeout-minutes: 10
              uses: ./.github/actions/kubernetes-ingress-cleanup
              with:
                  wait-for-dns-cleanup: 'false'  # No need to wait during setup cleanup

            - name: üèóÔ∏è Setup Ingress prerequisites for EKS domain setup
              if: ${{ matrix.distro.type == 'eks' && matrix.declination.name == 'domain' }}
              timeout-minutes: 15
              uses: ./.github/actions/aws-kubernetes-ingress-setup
              with:
                  cluster-name: ${{ matrix.distro.clusterName }}
                  scenario-short-name: ${{ matrix.scenario.shortName }}
                  aws-region: ${{ env.AWS_REGION }}
                  mail: admin@camunda.ie
                  tld: camunda.ie
                  ref-arch: eks-single-region
                  use-wildcard-cert: ${{ steps.cert-config.outputs.use-wildcard-cert }}
                  wildcard-cert-namespace: ${{ env.CAMUNDA_NAMESPACE }}
                  wildcard-cert-secret-name: ${{ env.WILDCARD_TLS_SECRET_NAME }}
                  vault-addr: ${{ secrets.VAULT_ADDR }}
                  vault-role-id: ${{ secrets.VAULT_ROLE_ID }}
                  vault-secret-id: ${{ secrets.VAULT_SECRET_ID }}

            - name: Prepare Keycloak configuration
              timeout-minutes: 5
              working-directory: ./generic/kubernetes/operator-based/keycloak/
              run: |
                  set -euo pipefail

                  # Determine which Keycloak configuration file to use
                  if [[ "${{ matrix.declination.name }}" == "domain" ]]; then
                      if [[ "${{ matrix.distro.type }}" == "openshift" ]]; then
                          echo "Using OpenShift route configuration"
                          KEYCLOAK_CONFIG_FILE="keycloak-instance-domain-openshift.yml"
                      else
                          echo "Using nginx ingress configuration"
                          KEYCLOAK_CONFIG_FILE="keycloak-instance-domain-nginx.yml"
                      fi
                  else
                      echo "Using no-domain localhost configuration"
                      KEYCLOAK_CONFIG_FILE="keycloak-instance-no-domain.yml"
                  fi

                  echo "KEYCLOAK_CONFIG_FILE=$KEYCLOAK_CONFIG_FILE" | tee -a "$GITHUB_ENV"
                  echo "Keycloak configuration file set: $KEYCLOAK_CONFIG_FILE"

                  # If using wildcard certificate, remove cert-manager annotations from Ingress
                  if [[ "${{ steps.cert-config.outputs.use-wildcard-cert }}" == "true" && "${{ matrix.declination.name }}" == "domain" ]]; then
                      echo "Removing cert-manager annotations from Keycloak Ingress (using wildcard certificate)"
                      envsubst < "$KEYCLOAK_CONFIG_FILE" | \
                          yq eval 'select(.kind == "Ingress") |= (
                            del(.metadata.annotations."kubernetes.io/tls-acme") |
                            del(.metadata.annotations."cert-manager.io/cluster-issuer") |
                            .spec.tls[0].secretName = "${{ env.WILDCARD_TLS_SECRET_NAME }}"
                          )' \
                          > keycloak-instance-processed.yml
                      echo "KEYCLOAK_CONFIG_FILE=keycloak-instance-processed.yml" | tee -a "$GITHUB_ENV"
                      echo "Processed Keycloak configuration saved to: keycloak-instance-processed.yml"
                  fi

            - name: Deploy all requirements using operator-based deployment
              timeout-minutes: 30
              working-directory: ./generic/kubernetes/operator-based/
              run: |
                  set -euo pipefail

                  echo "Deploying PostgreSQL clusters..."
                  if ! (cd postgresql && ./deploy.sh); then
                      echo "ERROR: PostgreSQL deployment failed"
                      kubectl get pods -n cnpg-system || true
                      kubectl get pods -n "$CAMUNDA_NAMESPACE" || true
                      exit 1
                  fi

                  echo "Deploying Elasticsearch cluster..."
                  if ! (cd elasticsearch && ./deploy.sh); then
                      echo "ERROR: Elasticsearch deployment failed"
                      kubectl get pods -n elastic-system || true
                      kubectl get pods -n "$CAMUNDA_NAMESPACE" || true
                      exit 1
                  fi

                  echo "Deploying Keycloak..."
                  if ! (cd keycloak && ./deploy.sh); then
                      echo "ERROR: Keycloak deployment failed"
                      kubectl get pods -n "$CAMUNDA_NAMESPACE" || true
                      exit 1
                  fi

                  echo "All operator-based infrastructure deployed successfully."

            - name: üîë Create Camunda credentials and export test tokens
              timeout-minutes: 5
              run: |
                  set -euo pipefail
                  echo "Creating Camunda Identity credentials..."
                  source .github/scripts/gha-functions.sh

                  export_new_env_vars ./generic/kubernetes/single-region/tests/procedure/generate-passwords.sh
                  ./generic/kubernetes/single-region/tests/procedure/create-keycloak-identity-secret.sh

            - name: Create test secrets (Docker registry & identity integration)
              if: env.TESTS_ENABLED == 'true'
              timeout-minutes: 2
              run: |
                  set -euo pipefail
                  echo "Creating Docker registry secrets to avoid rate limiting..."

                  # Create the pull secrets described in generic/kubernetes/operator-based/tests/helm-values/registry.yml
                  kubectl create secret docker-registry index-docker-io \
                      --docker-server=index.docker.io \
                      --docker-username="${{ steps.secrets.outputs.DOCKERHUB_USER }}" \
                      --docker-password="${{ steps.secrets.outputs.DOCKERHUB_PASSWORD }}" \
                      --namespace="$CAMUNDA_NAMESPACE" || true

                    kubectl create secret generic identity-secret-for-components-integration \
                        --from-literal=identity-admin-client-id="${{ steps.secrets.outputs.CI_CAMUNDA_USER_TEST_CLIENT_ID }}" \
                        --from-literal=identity-admin-client-secret="${{ steps.secrets.outputs.CI_CAMUNDA_USER_TEST_CLIENT_SECRET }}" \
                        --namespace="$CAMUNDA_NAMESPACE" ||true

            - name: üèóÔ∏è Deploy Camunda Platform
              timeout-minutes: 15
              working-directory: ./generic/kubernetes/operator-based/
              run: |
                  set -euo pipefail
                  echo "Deploying Camunda Platform with operator-based infrastructure..."

                  # Copy assembled values file to expected location
                  cp -f camunda-assembled-values.yml generated-values.yml

                  # Use the install-chart.sh script
                  ../single-region/procedure/install-chart.sh

            - name: üëÄ‚è≥ Wait for the deployment to be healthy
              timeout-minutes: 10
              working-directory: ./generic/kubernetes/operator-based/
              run: |
                  set -euo pipefail

                  # wait some time for the pods to spawn
                  sleep 30

                  cd tests && ./check-deployment-ready.sh && cd ..
                  echo "Camunda deployment verified successfully."

            - name: üîÑ Restart CoreDNS
              if: matrix.declination.name == 'domain' && env.CLEANUP_CLUSTERS == 'false'
              uses: ./.github/actions/kubernetes-restart-coredns
              timeout-minutes: 10
              with:
                  cluster-type: ${{ matrix.distro.type == 'openshift' && 'openshift' || 'kubernetes' }}

            - name: Set current Camunda version
              id: camunda-version
              run: |
                  set -euo pipefail
                  CAMUNDA_VERSION=$(cat .camunda-version)
                  echo "CAMUNDA_VERSION=$CAMUNDA_VERSION" | tee -a "$GITHUB_OUTPUT"

            - name: üß™ Run Camunda Platform tests
              if: env.TESTS_ENABLED == 'true'
              timeout-minutes: 60
              uses: ./.github/actions/internal-camunda-chart-tests
              with:
                  # Required inputs
                  camunda-version: ${{ steps.camunda-version.outputs.CAMUNDA_VERSION }}
                  secrets: ${{ toJSON(secrets) }}

                  # Test repository configuration
                  tests-camunda-helm-chart-repo-ref: ${{ env.TESTS_CAMUNDA_HELM_CHART_REPO_REF }}
                  tests-camunda-helm-chart-repo-path: ${{ env.TESTS_CAMUNDA_HELM_CHART_REPO_PATH }}

                  # Cluster configuration
                  test-cluster-type: ${{ env.TEST_CLUSTER_TYPE }}
                  test-namespace: ${{ env.CAMUNDA_NAMESPACE }}
                  test-release-name: ${{ env.CAMUNDA_RELEASE_NAME }}

                  # Domain configuration (for domain declination)
                  camunda-domain: ${{ matrix.declination.name == 'domain' && env.CAMUNDA_DOMAIN || '' }}
                  camunda-domain-grpc: ${{ matrix.declination.name == 'domain' && format('zeebe-{0}:443', env.CAMUNDA_DOMAIN) || '' }}

                  # Component configuration
                  webmodeler-enabled: 'true'      # Always enabled in operator-based deployment
                  console-enabled: 'true'         # Always enabled in operator-based deployment
                  elasticsearch-enabled: 'false'  # Using ECK operator instead

                  # Test configuration
                  enable-helm-chart-tests: 'true'
                  zeebe-authenticated: 'true' # we always have an auth provider
                  skip-c8sm-connectivity-ingress-class-check: ${{ matrix.distro.type == 'openshift' && 'true' || 'false' }}

                  # Service name for operator-based deployment
                  keycloak-service-name: keycloak-service:18080
                  elasticsearch-service-name: elasticsearch-es-http:9200

                  # Authentication tokens (from Vault secrets)
                  test-client-id: ${{ steps.secrets.outputs.CI_CAMUNDA_USER_TEST_CLIENT_ID }}
                  test-client-secret: ${{ steps.secrets.outputs.CI_CAMUNDA_USER_TEST_CLIENT_SECRET }}

            - name: üö®üî¨ Get failed Pods info
              if: failure()
              uses: ./.github/actions/internal-debug-failed-pods
              with:
                  namespace: ${{ env.CAMUNDA_NAMESPACE }}
                  artifact-suffix: ${{ matrix.distro.name }}-${{ matrix.scenario.name }}-${{ matrix.declination.name }}

    cleanup-clusters:
        name: Cleanup clusters
        if: always()
        runs-on: ubuntu-latest
        needs:
            - clusters-info
            - integration-tests
        strategy:
            fail-fast: false
            matrix:
                distro: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).distro }}
                scenario: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).scenario }}

        steps:
            - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6
              if: env.CLEANUP_CLUSTERS == 'true'
              with:
                  fetch-depth: 0

            - name: Install asdf tools with cache
              if: env.CLEANUP_CLUSTERS == 'true'
              uses: camunda/infraex-common-config/./.github/actions/asdf-install-tooling@193a21e1e56c9a65517a822224ac3b4ffa4d6ae4 # 1.5.9

            - name: Import Secrets
              id: secrets
              uses: hashicorp/vault-action@4c06c5ccf5c0761b6029f56cfb1dcf5565918a3b # v3
              if: env.CLEANUP_CLUSTERS == 'true'
              with:
                  url: ${{ secrets.VAULT_ADDR }}
                  method: approle
                  roleId: ${{ secrets.VAULT_ROLE_ID }}
                  secretId: ${{ secrets.VAULT_SECRET_ID }}
                  exportEnv: false
                  secrets: |
                      secret/data/products/infrastructure-experience/ci/common RH_OPENSHIFT_TOKEN;

            - name: Configure AWS CLI
              uses: ./.github/actions/aws-configure-cli
              if: env.CLEANUP_CLUSTERS == 'true'
              with:
                  vault-addr: ${{ secrets.VAULT_ADDR }}
                  vault-role-id: ${{ secrets.VAULT_ROLE_ID }}
                  vault-secret-id: ${{ secrets.VAULT_SECRET_ID }}
                  aws-profile: ${{ env.AWS_PROFILE }}
                  aws-region: ${{ env.AWS_REGION }}

            - name: Set current target branch
              if: env.CLEANUP_CLUSTERS == 'true'
              id: target-branch
              run: |
                  set -euo pipefail
                  TARGET_BRANCH=$(cat .target-branch)
                  echo "TARGET_BRANCH=$TARGET_BRANCH" | tee -a "$GITHUB_OUTPUT"

            - name: Delete on-demand ROSA HCP Cluster
              uses: ./.github/actions/aws-generic-terraform-cleanup
              if: always() && env.CLEANUP_CLUSTERS == 'true' && matrix.distro.type == 'openshift'
              timeout-minutes: 125
              env:
                  RHCS_TOKEN: ${{ steps.secrets.outputs.RH_OPENSHIFT_TOKEN }}
              with:
                  tf-bucket: ${{ env.S3_BACKEND_BUCKET }}
                  tf-bucket-region: ${{ env.S3_BUCKET_REGION }}
                  max-age-hours: 0
                  target: ${{ matrix.distro.clusterName }}-${{matrix.scenario.shortName }}
                  tf-bucket-key-prefix: ${{ env.S3_BACKEND_BUCKET_PREFIX_ROSA_HCP_SINGLE_REGION }}${{ steps.target-branch.outputs.TARGET_BRANCH }}/
                  openshift: 'true'
                  delete-ghost-rosa-clusters: 'false'
                  modules-order: vpn,cluster

            - name: Delete on-demand EKS Cluster
              uses: ./.github/actions/aws-generic-terraform-cleanup
              if: always() && env.CLEANUP_CLUSTERS == 'true' && matrix.distro.type == 'eks'
              timeout-minutes: 125
              with:
                  tf-bucket: ${{ env.S3_BACKEND_BUCKET }}
                  tf-bucket-region: ${{ env.S3_BUCKET_REGION }}
                  max-age-hours: 0
                  target: ${{ matrix.distro.clusterName }}-${{matrix.scenario.shortName }}
                  tf-bucket-key-prefix: ${{ env.S3_BACKEND_BUCKET_PREFIX_EKS_SINGLE_REGION }}${{ steps.target-branch.outputs.TARGET_BRANCH }}/
                  modules-order: vpn,cluster

    report-success:
        name: Report success
        runs-on: ubuntu-latest
        needs:
            - integration-tests
            - cleanup-clusters
        steps:
            - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6

            - name: Prevent other runs for renovate
              if: ${{ env.IS_RENOVATE_PR == 'true' }}
              env:
                  GH_TOKEN: ${{ github.token }}
              uses: ./.github/actions/internal-apply-skip-label

    report-failures:
        name: Report failures
        if: failure()
        runs-on: ubuntu-latest
        needs:
            - report-success
        steps:
            - name: Notify in Slack in case of failure
              id: slack-notification
              if: ${{ env.IS_SCHEDULE == 'true' }}
              uses: camunda/infraex-common-config/.github/actions/report-failure-on-slack@193a21e1e56c9a65517a822224ac3b4ffa4d6ae4 # 1.5.9
              with:
                  vault_addr: ${{ secrets.VAULT_ADDR }}
                  vault_role_id: ${{ secrets.VAULT_ROLE_ID }}
                  vault_secret_id: ${{ secrets.VAULT_SECRET_ID }}
