---
name: Tests - Integration - AWS OpenShift ROSA HCP Single Region

on:
    schedule:
        - cron: 0 3 * * 1 # Runs at 3 AM on Monday
    pull_request:
        paths:
            - .github/workflows/aws_openshift_rosa_hcp_single_region_tests.yml
            - .github/workflows-config/aws-openshift-rosa-hcp-single-region/test_matrix.yml
            - .tool-versions
            - generic/kubernetes/single-region/**
            - generic/openshift/single-region/**
            - aws/openshift/rosa-hcp-single-region/**
            - '!aws/openshift/rosa-hcp-single-region/test/golden/**'
            - .github/actions/aws-openshift-rosa-hcp-single-region-create/**
            - .github/actions/aws-openshift-rosa-hcp-single-region-cleanup/**
            - .github/actions/aws-configure-cli/**
            - .github/actions/internal-helm-chart-tests/**
            - .github/actions/internal-apply-skip-label/**

    workflow_dispatch:
        inputs:
            cluster_name:
                description: Cluster name.
                required: false
                type: string
            delete_clusters:
                description: Whether to delete the clusters.
                type: boolean
                default: true
            enable_tests:
                description: Whether to enable the tests.
                type: boolean
                default: true

# limit to a single execution per actor of this workflow
concurrency:
    group: ${{ github.workflow }}-${{ github.ref }}
    # in case of renovate we don't cancel the previous run, so it can finish it
    # otherwise weekly renovate PRs with tf docs updates result in broken clusters
    cancel-in-progress: ${{ !contains('renovate[bot]', github.actor) }}

env:
    IS_SCHEDULE: ${{ contains(github.head_ref, 'schedules/') || github.event_name == 'schedule' && 'true' || 'false' }}
    IS_RENOVATE_PR: ${{ github.event_name == 'pull_request' && github.event.pull_request.user.login == 'renovate[bot]' }}

    AWS_PROFILE: infex
    AWS_REGION: eu-west-2
    S3_BACKEND_BUCKET: tests-ra-aws-rosa-hcp-tf-state-eu-central-1
    S3_BUCKET_REGION: eu-central-1
    TF_MODULES_DIRECTORY: ./.tf-modules-workflow/   # where the tf repo will be clone
    S3_BACKEND_BUCKET_PREFIX: aws/openshift/rosa-hcp-single-region/ # keep it synced with the name of the module for simplicity

    CLEANUP_CLUSTERS: ${{ github.event.inputs.delete_clusters || 'true' }}

    # TEST VARIABLES

    # Vars with "CI_" prefix are used in the CI workflow only.
    CI_MATRIX_FILE: .github/workflows-config/aws-openshift-rosa-hcp-single-region/test_matrix.yml

    # Docker Hub auth to avoid image pull rate limit.
    # Vars with "TEST_" prefix are used in the test runner tool (Task).
    TESTS_ENABLED: ${{ github.event.inputs.enable_tests || 'true' }}
    # renovate: datasource=github-tags depName=camunda/camunda-platform-helm
    TESTS_CAMUNDA_HELM_CHART_REPO_REF: camunda-platform-8.7-12.0.1
    TESTS_CAMUNDA_HELM_CHART_REPO_PATH: ./.camunda_helm_repo   # where to clone it

    # Components that are not enabled by default in the doc, but enabled in our tests to have a better coverage
    WEBMODELER_ENABLED: 'true'
    CONSOLE_ENABLED: 'true'

    ROSA_CLI_VERSION: latest

jobs:
    triage:
        runs-on: ubuntu-latest
        outputs:
            should_skip: ${{ steps.skip_check.outputs.should_skip }}
        steps:
            - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4
            - name: Check labels
              id: skip_check
              uses: ./.github/actions/internal-triage-skip

    clusters-info:
        needs:
            - triage
        if: needs.triage.outputs.should_skip == 'false'
        name: Define Matrix
        runs-on: ubuntu-latest
        outputs:
            platform-matrix: ${{ steps.matrix.outputs.platform-matrix }}
        steps:
            - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4
              with:
                  fetch-depth: 0

            - name: Install asdf tools with cache
              uses: camunda/infraex-common-config/./.github/actions/asdf-install-tooling@14912e07221cd650bf9286e2a4733a138ca46374 # 1.3.6

            - id: matrix
              # we define a global matrix in an external file due to https://github.com/orgs/community/discussions/26284
              run: |
                  set -euo pipefail

                  # Generate cluster name.
                  # shellcheck disable=SC2086
                  distro_indexes="$(yq '.matrix.distro | to_entries | .[] | .key' ${CI_MATRIX_FILE})"

                  # Loop over clusters.
                  # Vars are exported to pass them to yq instead of local inline syntax.
                  # shellcheck disable=SC2086
                  for distro_index in ${distro_indexes}; do
                    cluster_name_input="${{ inputs.cluster_name }}"
                    cluster_name_fallback="hci-$(uuidgen | head -c 8)"

                    export cluster_name="${cluster_name_input:-${cluster_name_fallback}}"
                    export distro_index="${distro_index}"
                    yq -i '.matrix.distro[env(distro_index)].clusterName = env(cluster_name)' "${CI_MATRIX_FILE}"
                  done

                  echo "Filtering the matrix with strategy IS_SCHEDULE=$IS_SCHEDULE or IS_RENOVATE_PR=$IS_RENOVATE_PR"
                  if [[ "$IS_SCHEDULE" == "true" || "$IS_RENOVATE_PR" == "true" ]]; then
                    echo "This PR is scheduled or coming from renovate, we test all scenarios without filtering."
                    # shellcheck disable=SC2086
                    platform_matrix="$(yq '.matrix' --indent=0 --output-format json ${CI_MATRIX_FILE})"
                  else
                    # shellcheck disable=SC2086
                    platform_matrix="$(yq '(.matrix |= (.distro |= map(select(.schedule_only == null or .schedule_only == false)))) | .matrix' \
                      --indent=0 --output-format json ${CI_MATRIX_FILE})"
                  fi

                  echo "${platform_matrix}" | jq
                  echo "platform-matrix=${platform_matrix}" > "$GITHUB_OUTPUT"

    prepare-clusters:
        name: Prepare clusters
        needs:
            - clusters-info
        strategy:
            fail-fast: false
            matrix:
                distro: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).distro }}
                scenario: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).scenario }}
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4
              with:
                  ref: ${{ github.ref }}
                  fetch-depth: 0

            - name: Install asdf tools with cache
              uses: camunda/infraex-common-config/./.github/actions/asdf-install-tooling@14912e07221cd650bf9286e2a4733a138ca46374 # 1.3.6

            - name: Import Secrets
              id: secrets
              uses: hashicorp/vault-action@7709c609789c5e27b757a85817483caadbb5939a # v3
              with:
                  url: ${{ secrets.VAULT_ADDR }}
                  method: approle
                  roleId: ${{ secrets.VAULT_ROLE_ID }}
                  secretId: ${{ secrets.VAULT_SECRET_ID }}
                  exportEnv: false
                  secrets: |
                      secret/data/products/infrastructure-experience/ci/common RH_OPENSHIFT_TOKEN;
                      secret/data/products/infrastructure-experience/ci/common CI_OPENSHIFT_MAIN_PASSWORD;
                      secret/data/products/infrastructure-experience/ci/common CI_OPENSHIFT_MAIN_USERNAME;
                      secret/data/products/infrastructure-experience/ci/common CI_ENCRYPTION_KEY;

            - name: Configure AWS CLI
              uses: ./.github/actions/aws-configure-cli
              with:
                  vault-addr: ${{ secrets.VAULT_ADDR }}
                  vault-role-id: ${{ secrets.VAULT_ROLE_ID }}
                  vault-secret-id: ${{ secrets.VAULT_SECRET_ID }}
                  aws-profile: ${{ env.AWS_PROFILE }}
                  aws-region: ${{ env.AWS_REGION }}

            - name: Set current Camunda version
              id: camunda-version
              run: |
                  set -euo pipefail

                  CAMUNDA_VERSION=$(cat .camunda-version)
                  echo "CAMUNDA_VERSION=$CAMUNDA_VERSION" | tee -a "$GITHUB_OUTPUT"

            # Also remove the versioning
            - name: Create ROSA cluster and login
              uses: ./.github/actions/aws-openshift-rosa-hcp-single-region-create
              id: create_cluster
              # Do not interrupt tests; otherwise, the Terraform state may become inconsistent.
              if: always() && success()
              with:
                  rh-token: ${{ steps.secrets.outputs.RH_OPENSHIFT_TOKEN }}
                  cluster-name: ${{ matrix.distro.clusterName }}
                  admin-username: ${{ steps.secrets.outputs.CI_OPENSHIFT_MAIN_USERNAME }}
                  admin-password: ${{ steps.secrets.outputs.CI_OPENSHIFT_MAIN_PASSWORD }}
                  aws-region: ${{ env.AWS_REGION }}
                  s3-backend-bucket: ${{ env.S3_BACKEND_BUCKET }}
                  s3-bucket-region: ${{ env.S3_BUCKET_REGION }}
                  s3-bucket-key-prefix: ${{ env.S3_BACKEND_BUCKET_PREFIX }}${{ steps.camunda-version.outputs.CAMUNDA_VERSION }}/
                  openshift-version: ${{ matrix.distro.version }}
                  tf-modules-revision: ${{ github.ref }}
                  tf-modules-path: ${{ env.TF_MODULES_DIRECTORY }}
                  cleanup-tf-modules-path: 'false'

            - name: Export kubeconfig and encrypt it # this is required to pass matrix outputs securely using artifacts
              id: export_kube_config
              run: |
                  set -euo pipefail

                  # shellcheck disable=SC2005
                  kubectl config view --raw > kubeconfig.yaml 2>/dev/null
                  openssl enc -aes-256-cbc -salt -in kubeconfig.yaml -out encrypted_kubeconfig.enc -pass pass:"${{ steps.secrets.outputs.CI_ENCRYPTION_KEY }}" -pbkdf2
                  encrypted_kubeconfig_base64=$(base64 -w 0 encrypted_kubeconfig.enc)
                  echo "kubeconfig_raw=${encrypted_kubeconfig_base64}" >> "$GITHUB_OUTPUT"

            ## Write for matrix outputs workaround
            - uses: cloudposse/github-action-matrix-outputs-write@ed06cf3a6bf23b8dce36d1cf0d63123885bb8375 # v1
              id: out
              with:
                  matrix-step-name: ${{ github.job }}
                  matrix-key: ${{ matrix.distro.name }}-${{ matrix.scenario.name }}
                  outputs: |-
                      kubeconfig_raw: ${{ steps.export_kube_config.outputs.kubeconfig_raw }}

            - name: 🌐 Post-creation steps
              timeout-minutes: 20
              run: |
                  set -euo pipefail

                  # Here we verify the extraction of the env variables as presented in the documentation

                  cd ${{ env.TF_MODULES_DIRECTORY }}aws/openshift/${{ matrix.scenario.name }}/
                  source ./procedure/gather-cluster-login-id.sh
                  cd -

                  echo "CLUSTER_NAME=$CLUSTER_NAME"
                  echo "CLUSTER_API_URL=$CLUSTER_API_URL"

    access-info:
        name: Read kube configs from matrix
        runs-on: ubuntu-latest
        needs: prepare-clusters
        outputs:
            kubeconfig: ${{ steps.read-workflow.outputs.result }}
        steps:
            - uses: cloudposse/github-action-matrix-outputs-read@33cac12fa9282a7230a418d859b93fdbc4f27b5a # v1
              id: read-workflow
              with:
                  matrix-step-name: prepare-clusters

    integration-tests:
        name: Run integration tests - ${{ matrix.distro.name }} - ${{ matrix.scenario.name }} - ${{ matrix.declination.name }}
        runs-on: ubuntu-latest
        needs:
            - clusters-info
            - access-info
        strategy:
            fail-fast: false
            matrix:
                distro: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).distro }}
                scenario: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).scenario }}
                declination: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).declination }}
        concurrency:
            # instead of running sequentially in a matrix, we use concurrency to run the different scenarios
            # in parallel but the declinations sequentially
            # max-parallel would limit us to run 1 matrix job but this way we can run 2 jobs in parallel.
            group: ${{ github.workflow }}-${{ github.ref }}-${{ matrix.distro.name }}-${{ matrix.scenario.name }}
            cancel-in-progress: false
        env:
            # https://github.com/camunda/camunda-platform-helm/blob/test/integration/scenarios/chart-full-setup/Taskfile.yaml#L12C15-L12C32
            TEST_CLUSTER_TYPE: openshift
        steps:
            - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4

            - name: Install asdf tools with cache for the project
              uses: camunda/infraex-common-config/./.github/actions/asdf-install-tooling@14912e07221cd650bf9286e2a4733a138ca46374 # 1.3.6

            - name: Install CLI tools from OpenShift Mirror
              uses: redhat-actions/openshift-tools-installer@144527c7d98999f2652264c048c7a9bd103f8a82 # v1
              with:
                  oc: ${{ matrix.distro.version }}

            - name: Import Secrets
              id: secrets
              uses: hashicorp/vault-action@7709c609789c5e27b757a85817483caadbb5939a # v3
              with:
                  url: ${{ secrets.VAULT_ADDR }}
                  method: approle
                  roleId: ${{ secrets.VAULT_ROLE_ID }}
                  secretId: ${{ secrets.VAULT_SECRET_ID }}
                  exportEnv: false
                  secrets: |
                      secret/data/products/infrastructure-experience/ci/common DOCKERHUB_USER;
                      secret/data/products/infrastructure-experience/ci/common DOCKERHUB_PASSWORD;
                      secret/data/products/infrastructure-experience/ci/common CI_CAMUNDA_USER_TEST_CLIENT_ID;
                      secret/data/products/infrastructure-experience/ci/common CI_CAMUNDA_USER_TEST_CLIENT_SECRET;
                      secret/data/products/infrastructure-experience/ci/common CI_ENCRYPTION_KEY;

            - name: 🔐 Login into the cluster
              timeout-minutes: 10
              run: |
                  set -euo pipefail

                  mkdir -p "$HOME/.kube"
                  echo "${{
                      fromJson(needs.access-info.outputs.kubeconfig).kubeconfig_raw[
                        format('{0}-{1}', matrix.distro.name, matrix.scenario.name)
                      ]
                    }}" | base64 --decode > encrypted_kubeconfig.enc
                  openssl enc -aes-256-cbc -d -in encrypted_kubeconfig.enc -out "$HOME/.kube/config" -pass pass:"${{ steps.secrets.outputs.CI_ENCRYPTION_KEY }}" -pbkdf2
                  rm encrypted_kubeconfig.enc
                  chmod 600 "$HOME/.kube/config"

                  oc config current-context
                  oc get nodes

            - name: 📁 Get a copy of the reference architecture
              timeout-minutes: 10
              run: |
                  # run it as specified in the doc
                  set -euo pipefail

                  ./aws/openshift/${{ matrix.scenario.name }}/procedure/get-your-copy.sh
                  tree

            - name: 🌱 Register chart setup environment values
              timeout-minutes: 3
              run: |
                  set -euo pipefail

                  # the chart env should be loaded by the client at the very first step of his installation
                  source .github/scripts/gha-functions.sh
                  export_new_env_vars generic/openshift/single-region/procedure/chart-env.sh

            - name: 🏗️ Prepare a fresh namespace for the tests
              run: |
                  set -o errexit
                  set -euo pipefail

                  # Delete the namespace to ensure a fresh start
                  if kubectl get namespace "$CAMUNDA_NAMESPACE" &>/dev/null; then
                    kubectl delete namespace "$CAMUNDA_NAMESPACE" --wait
                    while kubectl get namespace "$CAMUNDA_NAMESPACE" &>/dev/null; do
                      echo "Namespace $CAMUNDA_NAMESPACE still being deleted, waiting..."
                      sleep 5
                    done
                  fi

                  oc new-project "$CAMUNDA_NAMESPACE" \
                    --description="Integration project of $CAMUNDA_NAMESPACE" \
                    --display-name="$CAMUNDA_NAMESPACE"

                  echo "Sleeping 30s"
                  sleep 30

            - name: 🛠️ Assemble deployment values of generic/openshift/single-region
              timeout-minutes: 10
              run: |
                  set -o errexit
                  set -euo pipefail

                  echo "Construct the values.yml file"

                  cp -f generic/openshift/single-region/helm-values/base.yml ./values.yml

                  echo "Applying declination: ${{ matrix.declination.name }}"

                  if [[ ${{ matrix.declination.name }} == "domain" ]]; then

                    source ./generic/openshift/single-region/procedure/setup-application-domain.sh
                    echo "CAMUNDA_DOMAIN=$DOMAIN_NAME" | tee -a "$GITHUB_ENV"
                    echo "CAMUNDA_GRPC_DOMAIN=zeebe-$DOMAIN_NAME:443" | tee -a "$GITHUB_ENV"

                    source ./generic/openshift/single-region/procedure/get-ingress-http2-status.sh

                    ./generic/openshift/single-region/procedure/enable-ingress-http2.sh

                    # Enable Routes
                    for file in zeebe-gateway-route.yml operate-route.yml tasklist-route.yml connectors-route.yml domain.yml; do
                        yq ". *d load(\"generic/openshift/single-region/helm-values/$file\")" values.yml > values-result.yml
                        cat values-result.yml && mv values-result.yml values.yml
                    done
                  elif [[ ${{ matrix.declination.name }} == "no-domain" ]]; then
                      # explicitely set no domain
                      echo "CAMUNDA_DOMAIN=" | tee -a "$GITHUB_ENV"
                      echo "CAMUNDA_GRPC_DOMAIN=" | tee -a "$GITHUB_ENV"

                      yq ". *d load(\"generic/openshift/single-region/helm-values/no-domain.yml\")" values.yml > values-result.yml
                      cat values-result.yml && mv values-result.yml values.yml
                  else
                    echo "Error: matrix.declaration must be set to 'domain' or 'no-domain'" >&2
                    exit 1
                  fi

                  # Enable SCC
                  yq '. *d load("generic/openshift/single-region/helm-values/scc.yml")' values.yml > values-result.yml
                  cat values-result.yml && mv values-result.yml values.yml

                  if [ "$WEBMODELER_ENABLED" == "true" ]; then
                    echo "Enabling WebModeler"
                    yq -i '.webModeler.enabled = true' values.yml
                    yq -i '.postgresql.enabled = true' values.yml
                  fi

                  if [ "$CONSOLE_ENABLED" == "true" ]; then
                    echo "Enabling Console"
                    yq -i '.console.enabled = true' values.yml
                  fi

                  # Add integration tests values
                  if [ "$TESTS_ENABLED" == "true" ]; then
                    for file in registry.yml identity.yml; do
                      yq ". *d load(\"generic/kubernetes/single-region/tests/helm-values/$file\")" values.yml > values-result.yml
                      cat values-result.yml && mv values-result.yml values.yml
                    done
                  fi

                  ./generic/openshift/single-region/procedure/assemble-envsubst-values.sh


            - name: 🏁 Install Camunda 8 using the generic/openshift helm chart procedure
              timeout-minutes: 10
              run: |
                  set -euo pipefail

                  source generic/openshift/single-region/procedure/generate-passwords.sh

                  ./generic/openshift/single-region/procedure/create-identity-secret.sh

                  # Generate tests objects
                  if [ "$TESTS_ENABLED" == "true" ]; then
                    # Create the pull secrets described in generic/kubernetes/single-region/tests/helm-values/registry.yml
                    kubectl create secret docker-registry index-docker-io \
                        --docker-server=index.docker.io \
                        --docker-username="${{ steps.secrets.outputs.DOCKERHUB_USER }}" \
                        --docker-password="${{ steps.secrets.outputs.DOCKERHUB_PASSWORD }}" \
                        --namespace="$CAMUNDA_NAMESPACE"

                    kubectl create secret generic identity-secret-for-components-integration \
                        --from-literal=identity-admin-client-id="${{ steps.secrets.outputs.CI_CAMUNDA_USER_TEST_CLIENT_ID }}" \
                        --from-literal=identity-admin-client-secret="${{ steps.secrets.outputs.CI_CAMUNDA_USER_TEST_CLIENT_SECRET }}" \
                        --namespace="$CAMUNDA_NAMESPACE"
                  fi

                  ./generic/openshift/single-region/procedure/install-chart.sh

            - name: 👀⏳ Wait for the deployment to be healthy using generic/kubernetes/single-region
              timeout-minutes: 10
              run: |
                  set -euo pipefail

                  ./generic/kubernetes/single-region/procedure/check-deployment-ready.sh

            - name: Set current Camunda version
              id: camunda-version
              run: |
                  set -euo pipefail

                  CAMUNDA_VERSION=$(cat .camunda-version)
                  echo "CAMUNDA_VERSION=$CAMUNDA_VERSION" | tee -a "$GITHUB_OUTPUT"


            - name: 🧪 Run Helm Chart tests
              if: env.TESTS_ENABLED == 'true'
              timeout-minutes: 60
              uses: ./.github/actions/internal-camunda-chart-tests
              with:
                  secrets: ${{ toJSON(secrets) }}
                  camunda-version: ${{ steps.camunda-version.outputs.CAMUNDA_VERSION }}
                  camunda-domain: ${{ env.CAMUNDA_DOMAIN }}
                  camunda-domain-grpc: ${{ env.CAMUNDA_GRPC_DOMAIN }}
                  webmodeler-enabled: ${{ env.WEBMODELER_ENABLED }}
                  console-enabled: ${{ env.CONSOLE_ENABLED }}
                  tests-camunda-helm-chart-repo-ref: ${{ env.TESTS_CAMUNDA_HELM_CHART_REPO_REF }}
                  tests-camunda-helm-chart-repo-path: ${{ env.TESTS_CAMUNDA_HELM_CHART_REPO_PATH }}
                  test-namespace: ${{ env.CAMUNDA_NAMESPACE }}
                  test-cluster-type: ${{ env.TEST_CLUSTER_TYPE }}
                  test-release-name: ${{ env.CAMUNDA_RELEASE_NAME }}

            - name: 🔬🚨 Get failed Pods info
              if: failure()
              run: |
                  set -euo pipefail

                  kubectl -n "$CAMUNDA_NAMESPACE" get po
                  kubectl -n "$CAMUNDA_NAMESPACE" get po | grep -v "Completed" | awk '/0\//{print $1}' | while read -r pod_name; do
                    echo -e "\n###Failed Pod: ${pod_name}###\n";
                    kubectl -n "$CAMUNDA_NAMESPACE" describe po "$pod_name";
                    kubectl -n "$CAMUNDA_NAMESPACE" logs "$pod_name";
                  done

    cleanup-clusters:
        name: Cleanup ROSA clusters
        if: always()
        runs-on: ubuntu-latest
        needs:
            - clusters-info
            - integration-tests
        strategy:
            fail-fast: false
            matrix:
                distro: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).distro }}
                scenario: ${{ fromJson(needs.clusters-info.outputs.platform-matrix).scenario }}

        steps:
            - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4
              if: env.CLEANUP_CLUSTERS == 'true'
              with:
                  fetch-depth: 0

            - name: Install asdf tools with cache
              if: env.CLEANUP_CLUSTERS == 'true'
              uses: camunda/infraex-common-config/./.github/actions/asdf-install-tooling@14912e07221cd650bf9286e2a4733a138ca46374 # 1.3.6

            - name: Import Secrets
              id: secrets
              uses: hashicorp/vault-action@7709c609789c5e27b757a85817483caadbb5939a # v3
              if: env.CLEANUP_CLUSTERS == 'true'
              with:
                  url: ${{ secrets.VAULT_ADDR }}
                  method: approle
                  roleId: ${{ secrets.VAULT_ROLE_ID }}
                  secretId: ${{ secrets.VAULT_SECRET_ID }}
                  exportEnv: false
                  secrets: |
                      secret/data/products/infrastructure-experience/ci/common RH_OPENSHIFT_TOKEN;

            - name: Configure AWS CLI
              uses: ./.github/actions/aws-configure-cli
              if: env.CLEANUP_CLUSTERS == 'true'
              with:
                  vault-addr: ${{ secrets.VAULT_ADDR }}
                  vault-role-id: ${{ secrets.VAULT_ROLE_ID }}
                  vault-secret-id: ${{ secrets.VAULT_SECRET_ID }}
                  aws-profile: ${{ env.AWS_PROFILE }}
                  aws-region: ${{ env.AWS_REGION }}

            - name: Set current Camunda version
              id: camunda-version
              if: env.CLEANUP_CLUSTERS == 'true'
              run: |
                  set -euo pipefail

                  CAMUNDA_VERSION=$(cat .camunda-version)
                  echo "CAMUNDA_VERSION=$CAMUNDA_VERSION" | tee -a "$GITHUB_OUTPUT"

            - name: Delete on-demand ROSA HCP Cluster
              uses: ./.github/actions/aws-openshift-rosa-hcp-single-region-cleanup
              if: always() && env.CLEANUP_CLUSTERS == 'true'
              timeout-minutes: 125
              env:
                  RHCS_TOKEN: ${{ steps.secrets.outputs.RH_OPENSHIFT_TOKEN }}
              with:
                  tf-bucket: ${{ env.S3_BACKEND_BUCKET }}
                  tf-bucket-region: ${{ env.S3_BUCKET_REGION }}
                  max-age-hours-cluster: 0
                  target: ${{ matrix.distro.clusterName }}
                  tf-bucket-key-prefix: ${{ env.S3_BACKEND_BUCKET_PREFIX }}${{ steps.camunda-version.outputs.CAMUNDA_VERSION }}/
                  delete-ghost-clusters: 'false'

    report-success:
        name: Report success
        runs-on: ubuntu-latest
        needs:
            - integration-tests
            - cleanup-clusters
        steps:
            - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4

            - name: Prevent other runs for renovate
              if: ${{ env.IS_RENOVATE_PR == 'true' }}
              env:
                  GH_TOKEN: ${{ github.token }}
              uses: ./.github/actions/internal-apply-skip-label

    report-failures:
        name: Report failures
        if: failure()
        runs-on: ubuntu-latest
        needs:
            - report-success
        steps:
            - name: Notify in Slack in case of failure
              id: slack-notification
              if: ${{ env.IS_SCHEDULE == 'true' }}
              uses: camunda/infraex-common-config/.github/actions/report-failure-on-slack@14912e07221cd650bf9286e2a4733a138ca46374 # 1.3.6
              with:
                  vault_addr: ${{ secrets.VAULT_ADDR }}
                  vault_role_id: ${{ secrets.VAULT_ROLE_ID }}
                  vault_secret_id: ${{ secrets.VAULT_SECRET_ID }}
